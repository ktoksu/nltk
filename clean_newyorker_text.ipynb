{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the *New Yorker* files needs to be cleaned of extraneous html and text before doing any NLTK text processing. I'm doing this in Python in order to get into the groove of using Python (I could do this MUCH more quickly in PHP).\n",
    "\n",
    "The current location of the file I'm starting with is:\n",
    "C:\\Users\\ktoks\\Desktop\\new_yorker_1-10_to-clean_ansi.txt\n",
    "\n",
    "This file contains 98 stories ranging datewise from 09-28-2015 to 11-04-2013. Word count is computed in the code, below.\n",
    "\n",
    "I've saved the file as an ANSI text, instead of its original UTF-8 encoding, in order to get rid of some extraneous encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line count is: 20\n",
      "Word count is: 531362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\kt\\\\Desktop\\\\new_yorker_fiction\\\\ipython_docs\\\\new_yorker_1-10_to-clean_ansi.txt', 'r') as f:\n",
    "    newyorker_data_1 = f.readlines()\n",
    "f.closed\n",
    "# print(newyorker_data_1)\n",
    "\n",
    "num_words = num_lines = 0  # chain assignment\n",
    "for line in newyorker_data_1:\n",
    "       num_lines += 1\n",
    "       line = line.strip()\n",
    "       words = line.split()\n",
    "       num_words += len(words)\n",
    "print(\"Line count is:\", num_lines)\n",
    "print(\"Word count is:\", num_words)\n",
    "\n",
    "type(newyorker_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '<a href' in file: 178\n",
      "Number of '<td>' in file: 721\n"
     ]
    }
   ],
   "source": [
    "f = open(\"C:\\\\Users\\\\kt\\\\Desktop\\\\new_yorker_fiction\\\\ipython_docs\\\\new_yorker_1-10_to-clean_ansi.txt\", 'r')\n",
    "contents_infile = f.read()\n",
    "f.close()\n",
    "print(\"Number of '<a href' in file:\", contents_infile.count(\"<a href\"))\n",
    "print(\"Number of '<td>' in file:\", contents_infile.count(\"<td>\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '<a href' in file: 6\n",
      "Number of '<td>' in file: 20\n"
     ]
    }
   ],
   "source": [
    "f = open(\"C:\\\\Users\\\\kt\\\\Desktop\\\\replace-test.txt\", 'r')\n",
    "contents_infile = f.read()\n",
    "f.close()\n",
    "print(\"Number of '<a href' in file:\", contents_infile.count(\"<a href\"))\n",
    "print(\"Number of '<td>' in file:\", contents_infile.count(\"<td>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "infile = open('C:\\\\Users\\\\kt\\\\Desktop\\\\replace-test.txt', 'r')\n",
    "outfile = open('C:\\\\Users\\\\kt\\\\Desktop\\\\new.txt', 'w')\n",
    "pattern = re.compile('<a href.+?</a>', re.IGNORECASE)\n",
    "for line in infile:\n",
    "    if re.search(pattern, line):\n",
    "        print(pattern.sub('', line), end='', file=outfile)\n",
    "print(' Done.')\n",
    "infile.close()\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "This all the extraneous text we need to get rid of:\n",
    "\n",
    "1.\n",
    "♦ Sign up for the daily newsletter.Sign up for the daily newsletter: the best of The New Yorker every day. E-mail address GO SIGN UP Share Tweet\n",
    "♦ (Translated, from the Japanese, by Ted Goossen.) Sign up for the daily newsletter.Sign up for the daily newsletter: the best of The New Yorker every day. E-mail address GO SIGN UP Share Tweet\n",
    "\n",
    "2.\n",
    "Credit Design by \n",
    "Credit Illustration by \n",
    "Credit Photograph by \n",
    "\n",
    "b'\\xff\\xfeW['.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "infile = open('C:\\\\Users\\\\kt\\\\Desktop\\\\new1-10.txt', 'r')\n",
    "outfile = open('C:\\\\Users\\\\kt\\\\Desktop\\\\new.txt', 'w')\n",
    "pattern = re.compile('.?\\?.?</td><td>', re.IGNORECASE)\n",
    "x = 0\n",
    "for line in infile:\n",
    "    if re.search(pattern, line):\n",
    "        print(pattern.sub('', line), end='', file=outfile)\n",
    "        x += 1\n",
    "print('x = ', x)\n",
    "infile.close()\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I want to test encoding.  In Python3, it should be utf-8 by default.\n",
    "\n",
    "I'm looking for:  ♦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-23-178aa85ed66c>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-178aa85ed66c>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    print(♦)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "f = open('C:\\\\Users\\\\kt\\\\Desktop\\\\test_encoding_pp1-10.txt')\n",
    "for line in f:\n",
    "    match = re.search(r'♦', line)\n",
    "    if match:\n",
    "        print(match.group())\n",
    "f.close()\n",
    "\n",
    "print(♦)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_charref(self, name):\n",
    "        print(\"Encountered an entity: \", name)\n",
    "\n",
    "parser = MyHTMLParser()\n",
    "parser.feed('♦ Sign up for the daily newsletter.Sign up')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
